{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a new workspacwee using SDK\n",
    "* Automatically creates a new workspace for us\n",
    "* Remeber when you run the script below, there will be authentication steps\n",
    "* Once workspace is created cpu, gpu ( compute target for training and predicting your models) will be made available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying StorageAccount with name myworkspstorage73fec2c74.\n",
      "Deploying AppInsights with name myworkspinsights0010dae8.\n",
      "Deployed AppInsights with name myworkspinsights0010dae8. Took 2.85 seconds.\n",
      "Deploying KeyVault with name myworkspkeyvault85469494.\n",
      "Deployed KeyVault with name myworkspkeyvault85469494. Took 16.87 seconds.\n",
      "Deployed StorageAccount with name myworkspstorage73fec2c74. Took 23.62 seconds.\n",
      "Deploying Workspace with name myworkspace2.\n",
      "Deployed Workspace with name myworkspace2. Took 18.58 seconds.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.create(name='myworkspace2',\n",
    "               subscription_id='ff711122-6294-4fad-9d1f-bf505a51fc42',\n",
    "               resource_group='mlproject',\n",
    "               create_resource_group=False,\n",
    "               location='westus2'\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "ws = Workspace.get(\"myworkspace2\", subscription_id='ff711122-6294-4fad-9d1f-bf505a51fc42',\n",
    "               resource_group='mlproject',\n",
    "               location='westus2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Config File\n",
    "To use the same workspace in multiple environments, create a JSON configuration file. The configuration file saves your subscription, resource, and workspace name so that it can be easily loaded. To save the configuration use the write_config method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws.write_config(path='C:/Users/User/Desktop', file_name=\"ws_config.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the workspace from the saved config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use Azure ML 1.32.0 to work with myworkspace2\n"
     ]
    }
   ],
   "source": [
    "ws = Workspace.from_config('C:/Users/User/Desktop/.azureml/ws_config.json')\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile my_sklearn_lr.py\n",
    "# # Load the libraries\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import os\n",
    "# import sklearn\n",
    "# import joblib\n",
    "# import datetime\n",
    "# from azureml.core import Run\n",
    "# run = Run.get_context()\n",
    "# # Load Boston data\n",
    "# from sklearn.datasets import load_boston\n",
    "# boston_dataset = load_boston()\n",
    "# # Train test split data\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# num_Rooms_Train, num_Rooms_Test, med_price_Train, med_Price_Test = train_test_split(boston_dataset.data[:,5].reshape(-1,1), boston_dataset.target.reshape(-1,1))\n",
    "# # Create Linear Regression model\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# price_room = LinearRegression()\n",
    "# price_room.fit (num_Rooms_Train,med_price_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the libraries\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import os\n",
    "# import sklearn\n",
    "# import joblib\n",
    "# import datetime\n",
    "# from azureml.core import Run\n",
    "# run = Run.get_context()\n",
    "# run.log(\"Training start time\", str(datetime.datetime.now()))\n",
    "# # Load Boston data\n",
    "# from sklearn.datasets import load_boston\n",
    "# boston_dataset = load_boston()\n",
    "# # Train test split data\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# num_Rooms_Train, num_Rooms_Test, med_price_Train, med_Price_Test = train_test_split(boston_dataset.data[:,5].reshape(-1,1), boston_dataset.target.reshape(-1,1))\n",
    "# # Create Linear Regression model\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# price_room = LinearRegression()\n",
    "# result=price_room.fit (num_Rooms_Train,med_price_Train)\n",
    "# run.log('Score :', result)\n",
    "# run.log(\"Training end time\", str(datetime.datetime.now()))\n",
    "# run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8021212121212121"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "dataframe=pd.read_csv('C:/Users/User/Desktop/Data/diabetes.csv')\n",
    "\n",
    "cols=['Pregnancies', 'PlasmaGlucose', 'DiastolicBloodPressure',\n",
    "       'TricepsThickness', 'SerumInsulin', 'BMI', 'DiabetesPedigree', 'Age',\n",
    "       'Diabetic']\n",
    "\n",
    "dataframe=dataframe[cols]\n",
    "\n",
    "\n",
    "X_df=dataframe[['Pregnancies', 'PlasmaGlucose', 'DiastolicBloodPressure','TricepsThickness', 'SerumInsulin', 'BMI', 'DiabetesPedigree', 'Age']]\n",
    "Y_df=dataframe['Diabetic']\n",
    "\n",
    "X=X_df.values\n",
    "Y=Y_df.values\n",
    "\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "rescaledX=scaler.fit_transform(X)\n",
    "\n",
    "test_size=0.33\n",
    "seed=7\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=test_size,random_state=seed)\n",
    "\n",
    "model=LogisticRegression(max_iter=100000)\n",
    "model.fit(X_train,Y_train)\n",
    "result=model.score(X_test,Y_test)\n",
    "result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes_pipeline\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Create a folder for the pipeline step files\n",
    "experiment_folder = 'diabetes_pipeline'\n",
    "os.makedirs(experiment_folder, exist_ok=True)\n",
    "\n",
    "print(experiment_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prep Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing diabetes_pipeline/prep_data_diabetes.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/prep_data_diabetes.py\n",
    "# Import libraries\n",
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from azureml.core import Run\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "dataframe=pd.read_csv('C:/Users/User/Desktop/Data/diabetes.csv')\n",
    "# Normalize the numeric columns\n",
    "scaler = MinMaxScaler()\n",
    "num_cols = ['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree']\n",
    "dataframe[num_cols] = scaler.fit_transform(dataframe[num_cols])\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "# Log processed rows\n",
    "row_count = (len(dataframe))\n",
    "run.log('processed_rows', row_count)\n",
    "# remove nulls\n",
    "dataframe = dataframe.dropna()\n",
    "# Log processed rows\n",
    "row_count = (len(dataframe))\n",
    "run.log('processed_rows', row_count)\n",
    "\n",
    "# Save the prepped data\n",
    "print(\"Saving Data...\")\n",
    "os.makedirs(experiment_folder, exist_ok=True)\n",
    "save_path = os.path.join(experiment_folder,'data.csv')\n",
    "dataframe.to_csv(save_path, index=False, header=True)\n",
    "\n",
    "# End the run\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Prep Data Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientID</th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>PlasmaGlucose</th>\n",
       "      <th>DiastolicBloodPressure</th>\n",
       "      <th>TricepsThickness</th>\n",
       "      <th>SerumInsulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigree</th>\n",
       "      <th>Age</th>\n",
       "      <th>Diabetic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1354778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.858108</td>\n",
       "      <td>0.602151</td>\n",
       "      <td>0.317647</td>\n",
       "      <td>0.011509</td>\n",
       "      <td>0.668950</td>\n",
       "      <td>0.510511</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1147438</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.028133</td>\n",
       "      <td>0.080345</td>\n",
       "      <td>0.036123</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PatientID  Pregnancies  PlasmaGlucose  DiastolicBloodPressure  \\\n",
       "0    1354778     0.000000       0.858108                0.602151   \n",
       "1    1147438     0.571429       0.324324                0.741935   \n",
       "\n",
       "   TricepsThickness  SerumInsulin       BMI  DiabetesPedigree  Age  Diabetic  \n",
       "0          0.317647      0.011509  0.668950          0.510511   21         0  \n",
       "1          0.470588      0.028133  0.080345          0.036123   23         0  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the prepared data file in the training folder\n",
    "print(\"Loading Data...\")\n",
    "file_path = os.path.join(experiment_folder,'data.csv')\n",
    "diabetes = pd.read_csv(file_path)\n",
    "diabetes.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes_pipeline\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Create a folder for the pipeline step files\n",
    "experiment_folder = 'diabetes_pipeline'\n",
    "os.makedirs(experiment_folder, exist_ok=True)\n",
    "\n",
    "print(experiment_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile $experiment_folder/prep_diabetes.py\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import os\n",
    "# import sklearn\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# dataframe=pd.read_csv('C:/Users/User/Desktop/Data/diabetes.csv')\n",
    "\n",
    "# cols=['Pregnancies', 'PlasmaGlucose', 'DiastolicBloodPressure',\n",
    "#        'TricepsThickness', 'SerumInsulin', 'BMI', 'DiabetesPedigree', 'Age',\n",
    "#        'Diabetic']\n",
    "\n",
    "# dataframe=dataframe[cols]\n",
    "\n",
    "\n",
    "# X_df=dataframe[['Pregnancies', 'PlasmaGlucose', 'DiastolicBloodPressure','TricepsThickness', 'SerumInsulin', 'BMI', 'DiabetesPedigree', 'Age']]\n",
    "# Y_df=dataframe['Diabetic']\n",
    "\n",
    "# X=X_df.values\n",
    "# Y=Y_df.values\n",
    "\n",
    "# scaler=MinMaxScaler(feature_range=(0,1))\n",
    "# rescaledX=scaler.fit_transform(X)\n",
    "\n",
    "# test_size=0.33\n",
    "# seed=7\n",
    "# X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=test_size,random_state=seed)\n",
    "\n",
    "# model=LogisticRegression(max_iter=100000)\n",
    "# model.fit(X_train,Y_train)\n",
    "# # result=model.score(X_test,Y_test)\n",
    "# # result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data...\n",
      "Training a decision tree model...\n",
      "Accuracy: 0.8873333333333333\n",
      "Attempted to log scalar metric Accuracy:\n",
      "0.8873333333333333\n",
      "AUC: 0.873142942434947\n",
      "Attempted to log scalar metric AUC:\n",
      "0.873142942434947\n",
      "Attempted to log image metric ROC:\n",
      "Figure(432x288)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Registering model diabetes\n"
     ]
    }
   ],
   "source": [
    "# %%writefile $experiment_folder/train_diabetes.py\n",
    "# Import libraries\n",
    "from azureml.core import Run, Model\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# load the prepared data file in the training folder\n",
    "# load the prepared data file in the training folder\n",
    "print(\"Loading Data...\")\n",
    "file_path = os.path.join(experiment_folder,'data.csv')\n",
    "diabetes = pd.read_csv(file_path)\n",
    "\n",
    "# Separate features and labels\n",
    "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# Train adecision tree model\n",
    "print('Training a decision tree model...')\n",
    "model = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "run.log('Accuracy', np.float(acc))\n",
    "\n",
    "# calculate AUC\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC: ' + str(auc))\n",
    "run.log('AUC', np.float(auc))\n",
    "\n",
    "# plot ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])\n",
    "fig = plt.figure(figsize=(6, 4))\n",
    "# Plot the diagonal 50% line\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "# Plot the FPR and TPR achieved by our model\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "run.log_image(name = \"ROC\", plot = fig)\n",
    "plt.show()\n",
    "\n",
    "# Save the trained model in the outputs folder\n",
    "print(\"Saving model...\")\n",
    "os.makedirs('diabetes_pipeline', exist_ok=True)\n",
    "model_file = os.path.join('diabetes_pipeline', 'diabetes_model.pkl')\n",
    "joblib.dump(value=model, filename=model_file)\n",
    "\n",
    "# Registering Model into Workspace\n",
    "# With your model saved as a pickle file, you can upload it into your workspace:\n",
    "from azureml.core.model import Model\n",
    "model = Model.register(workspace=ws, model_path=\"./diabetes_pipeline/diabetes_model.pkl\", model_name=\"diabetes\")\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model\n",
    "Now that you have a model named price_room, let’s save this model as a pickle file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "# os.makedirs(\"diabetes_pipeline\", exist_ok=True)\n",
    "# joblib.dump(value=model, filename=\"diabetes_pipeline/diabetes.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Registering Model into Workspace\n",
    "With your model saved as a pickle file, you can upload it into your workspace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model diabetes\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.model import Model\n",
    "model = Model.register(workspace=ws, model_path=\"./diabetes_pipeline/diabetes_model.pkl\", model_name=\"diabetes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies\n",
    "For your model to work in the cloud, you need to specify the dependencies. Treat dependencies as a grocery shopping list. You tell the program what kind of grocery/libraries you need for you to cook a meal/train your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import *\n",
    "import azureml.dataprep as dprep\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Pipeline¶\n",
    "You can perform the various steps required to ingest data, train a model, and register the model individually by using the Azure ML SDK to run script-based experiments. However, in an enterprise environment it is common to encapsulate the sequence of discrete steps required to build a machine learning solution into a pipeline that can be run on one or more compute targets; either on-demand by a user, from an automated build process, or on a schedule.\n",
    "\n",
    "In this notebook, you'll bring together all of these elements to create a simple pipeline that pre-processes data and then trains and registers a model.\n",
    "\n",
    "# Connect to your workspace\n",
    "To get started, connect to your workspace.\n",
    "\n",
    "Note: If you haven't already established an authenticated session with your Azure subscription, you'll be prompted to authenticate by clicking a link, entering an authentication code, and signing into Azure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use Azure ML 1.32.0 to work with myworkspace2\n"
     ]
    }
   ],
   "source": [
    "ws = Workspace.get(\"myworkspace2\", subscription_id='ff711122-6294-4fad-9d1f-bf505a51fc42',\n",
    "               resource_group='mlproject',\n",
    "               location='westus2')\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by creating a new Jupyter Notebook and follow the below steps. Run each of these blocks in a separate Notebook cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the Data\n",
    "We are now ready to associate the pipeline with a compute environment. The below snippet will either launch a new compute cluster or attaches itself to an existing one.\n",
    "What if your computer only has 2GB of RAM (I believe this is highly unlikely…)? You can train your model with resources provided by Azure ML Services instead of using your local resources. After importing the relevant libraries, you can take a look at all the virtual machines that are available for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 1.32.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import azureml.core\n",
    "from azureml.core import Workspace, Experiment, Datastore\n",
    "from azureml.widgets import RunDetails\n",
    " \n",
    "from azureml.core import Dataset\n",
    " \n",
    "from azureml.pipeline.core import Pipeline, PipelineData\n",
    "from azureml.pipeline.core import PipelineRun, StepRun, PortDataReference\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    " \n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    " \n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    " \n",
    "from azureml.core.model import Model\n",
    " \n",
    "# Check core SDK version number\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>vCPUs</th>\n",
       "      <th>gpus</th>\n",
       "      <th>memoryGB</th>\n",
       "      <th>maxResourceVolumeMB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Standard_E2a_v4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>51200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Standard_E4a_v4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>102400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Standard_E8a_v4</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>204800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Standard_E16a_v4</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>409600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Standard_E32a_v4</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>819200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Standard_ND24rs</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>448.0</td>\n",
       "      <td>1376256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Standard_ND24s</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>448.0</td>\n",
       "      <td>1376256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Standard_NV12s_v3</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>112.0</td>\n",
       "      <td>344064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Standard_NV24s_v3</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>224.0</td>\n",
       "      <td>688128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Standard_NV48s_v3</td>\n",
       "      <td>48</td>\n",
       "      <td>4</td>\n",
       "      <td>448.0</td>\n",
       "      <td>1376256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>113 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name  vCPUs  gpus  memoryGB  maxResourceVolumeMB\n",
       "0      Standard_E2a_v4      2     0      16.0                51200\n",
       "1      Standard_E4a_v4      4     0      32.0               102400\n",
       "2      Standard_E8a_v4      8     0      64.0               204800\n",
       "3     Standard_E16a_v4     16     0     128.0               409600\n",
       "4     Standard_E32a_v4     32     0     256.0               819200\n",
       "..                 ...    ...   ...       ...                  ...\n",
       "108    Standard_ND24rs     24     4     448.0              1376256\n",
       "109     Standard_ND24s     24     4     448.0              1376256\n",
       "110  Standard_NV12s_v3     12     1     112.0               344064\n",
       "111  Standard_NV24s_v3     24     2     224.0               688128\n",
       "112  Standard_NV48s_v3     48     4     448.0              1376256\n",
       "\n",
       "[113 rows x 5 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.compute import AmlCompute\n",
    "list_vms = AmlCompute.supported_vmsizes(workspace=ws)\n",
    "# print(list_vms)\n",
    "# print(type(list_vms))\n",
    "import pandas as pd\n",
    "pd.DataFrame(list_vms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload Dataset from the local direcotry to the workspace default storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"workspaceblobstore\",\n",
      "  \"container_name\": \"azureml-blobstore-36b94137-43b8-49db-b607-c868473eda05\",\n",
      "  \"account_name\": \"myworkspstorage73fec2c74\",\n",
      "  \"protocol\": \"https\",\n",
      "  \"endpoint\": \"core.windows.net\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Dataset\n",
    "default_ds = ws.get_default_datastore()\n",
    "print(default_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataupload(filename):\n",
    "    if 'diabetes dataset' not in ws.datasets:\n",
    "        default_ds.upload_files(files=[filename], # Upload the diabetes csv files in /data\n",
    "                            target_path='diabetes-data/', # Put it in a folder path in the datastore\n",
    "                            overwrite=True, # Replace existing files of the same name\n",
    "                            show_progress=True)\n",
    "\n",
    "    #Create a tabular dataset from the path on the datastore (this may take a short while)\n",
    "        tab_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'diabetes-data/*.csv'))\n",
    "\n",
    "    # Register the tabular dataset\n",
    "        try:\n",
    "            tab_data_set = tab_data_set.register(workspace=ws, \n",
    "                                    name='diabetes dataset',\n",
    "                                    description='diabetes data',\n",
    "                                    tags = {'format':'CSV'},\n",
    "                                    create_new_version=True)\n",
    "            print('Dataset registered.')\n",
    "        except Exception as ex:\n",
    "            print(ex)\n",
    "    else:\n",
    "        print('Dataset already registered.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already registered.\n"
     ]
    }
   ],
   "source": [
    "dataupload('C:/Users/User/Desktop/Data/diabetes.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already registered.\n"
     ]
    }
   ],
   "source": [
    "dataupload('C:/Users/User/Desktop/Data/diabetes2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already registered.\n"
     ]
    }
   ],
   "source": [
    "# Load Data Prep Data\n",
    "dataupload('C:/Users/User/Desktop/Data/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if 'diabetes dataset' not in ws.datasets:\n",
    "#     default_ds.upload_files(files=['C:/Users/User/Desktop/ML Projects in Git/Azure-Machine-Learning-Service/diabetes_pipeline/data.csv'], # Upload the diabetes csv files in /data\n",
    "#                         target_path='diabetes-data/', # Put it in a folder path in the datastore\n",
    "#                         overwrite=True, # Replace existing files of the same name\n",
    "#                         show_progress=True)\n",
    "\n",
    "#     #Create a tabular dataset from the path on the datastore (this may take a short while)\n",
    "#     tab_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'diabetes-data/*.csv'))\n",
    "\n",
    "#     # Register the tabular dataset\n",
    "#     try:\n",
    "#         tab_data_set = tab_data_set.register(workspace=ws, \n",
    "#                                 name='diabetes dataset',\n",
    "#                                 description='diabetes data',\n",
    "#                                 tags = {'format':'CSV'},\n",
    "#                                 create_new_version=True)\n",
    "#         print('Dataset registered.')\n",
    "#     except Exception as ex:\n",
    "#         print(ex)\n",
    "# else:\n",
    "#     print('Dataset already registered.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Provisioning Compute environment\n",
    "We are now ready to associate the pipeline with a compute environment. The below snippet will either launch a new compute cluster or attaches itself to an existing one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found existing compute target.\n",
      "Azure Machine Learning Compute attached\n"
     ]
    }
   ],
   "source": [
    "aml_compute_target = \"demo-cluster\"\n",
    "try:\n",
    "    aml_compute = AmlCompute(ws, aml_compute_target)\n",
    "    print(\"found existing compute target.\")\n",
    "except ComputeTargetException:\n",
    "    print(\"creating new compute target\")\n",
    "    \n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = \"STANDARD_D2_V2\",\n",
    "                                                                min_nodes = 1, \n",
    "                                                                max_nodes = 2)    \n",
    "    aml_compute = ComputeTarget.create(ws, aml_compute_target, provisioning_config)\n",
    "    aml_compute.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "    \n",
    "print(\"Azure Machine Learning Compute attached\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Environemnt and Dependencies for the Pipeline\n",
    "For this, we will build a custom Docker image with appropriate pip and Conda modules. The steps of the pipeline will leverage\n",
    "this image during the runtime.\n",
    "The compute will require a Python environment with the necessary package dependencies installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting diabetes_pipeline/experiment_env.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/experiment_env.yml\n",
    "name: experiment_env\n",
    "dependencies:\n",
    "- python=3.6.2\n",
    "- scikit-learn\n",
    "- ipykernel\n",
    "- matplotlib\n",
    "- pandas\n",
    "- pip\n",
    "- pip:\n",
    "  - azureml-defaults\n",
    "  - pyarrow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have a Conda configuration file, you can create an environment and use it in the run configuration for the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run configuration created.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "\n",
    "# Create a Python environment for the experiment (from a .yml file)\n",
    "experiment_env = Environment.from_conda_specification(\"experiment_env\", experiment_folder + \"/experiment_env.yml\")\n",
    "\n",
    "# Register the environment \n",
    "experiment_env.register(workspace=ws)\n",
    "registered_env = Environment.get(ws, 'experiment_env')\n",
    "\n",
    "# Create a new runconfig object for the pipeline\n",
    "pipeline_run_config = RunConfiguration()\n",
    "\n",
    "# Use the compute you created above. \n",
    "pipeline_run_config.target = aml_compute\n",
    "\n",
    "# Assign the environment to the run configuration\n",
    "pipeline_run_config.environment = registered_env\n",
    "\n",
    "print (\"Run configuration created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Under environments view the docker file and build your docker image in the portal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and run a pipeline\n",
    "Now you're ready to create and run a pipeline.\n",
    "\n",
    "First you need to define the steps for the pipeline, and any data references that need to be passed between them. In this case, the first step must write the prepared data to a folder that can be read from by the second step. Since the steps will be run on remote compute (and in fact, could each be run on different compute), the folder path must be passed as a data reference to a location in a datastore within the workspace. The OutputFileDatasetConfig object is a special kind of data reference that is used for interim storage locations that can be passed between pipeline steps, so you'll create one and use at as the output for the first step and the input for the second step. Note that you need to pass it as a script argument so your code can access the datastore location referenced by the data reference.\n",
    "\n",
    "This article will show you how to:\n",
    "\n",
    "Use Dataset objects for pre-existing data\n",
    "Access data within your steps\n",
    "Split Dataset data into subsets, such as training and validation subsets\n",
    "Create OutputFileDatasetConfig objects to transfer data to the next pipeline step\n",
    "Use OutputFileDatasetConfig objects as input to pipeline steps\n",
    "Create new Dataset objects from OutputFileDatasetConfig you wish to persist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"source\": [\n",
       "    \"('workspaceblobstore', 'diabetes-data/diabetes.csv')\"\n",
       "  ],\n",
       "  \"definition\": [\n",
       "    \"GetDatastoreFiles\",\n",
       "    \"ParseDelimited\",\n",
       "    \"DropColumns\",\n",
       "    \"SetColumnTypes\"\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diab_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'diabetes-data/diabetes.csv'))\n",
    "diab_data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"source\": [\n",
       "    \"('workspaceblobstore', 'diabetes-data/data.csv')\"\n",
       "  ],\n",
       "  \"definition\": [\n",
       "    \"GetDatastoreFiles\",\n",
       "    \"ParseDelimited\",\n",
       "    \"DropColumns\",\n",
       "    \"SetColumnTypes\"\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diab_data_prep = Dataset.Tabular.from_delimited_files(path=(default_ds, 'diabetes-data/data.csv'))\n",
    "diab_data_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.data import OutputFileDatasetConfig\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "\n",
    "# Get the training dataset\n",
    "diabetes_ds = ws.datasets.get(\"diabetes dataset\")\n",
    "\n",
    "# Create an OutputFileDatasetConfig (temporary Data Reference) for data passed from step 1 to step 2\n",
    "prepped_data = OutputFileDatasetConfig(\"prepped_data\")\n",
    "\n",
    "# Step 1, Run the data prep script\n",
    "prep_step = PythonScriptStep(name = \"Prepare Data\",\n",
    "                                source_directory = experiment_folder,\n",
    "                                script_name = \"prep_data_diabetes.py\",\n",
    "                                inputs=[diab_data_prep.as_named_input('data')],\n",
    "                                compute_target = aml_compute,\n",
    "                                runconfig = pipeline_run_config,\n",
    "                                allow_reuse = True)\n",
    "\n",
    "# Step 2, run the training script\n",
    "train_step = PythonScriptStep(name = \"Train and Register Model\",\n",
    "                                source_directory = experiment_folder,\n",
    "                                script_name = \"prep_diabetes.py\",\n",
    "                                inputs=[diab_data_set.as_named_input('diabetes')],\n",
    "                                compute_target = aml_compute,\n",
    "                                runconfig = pipeline_run_config,\n",
    "                                allow_reuse = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datastore = Datastore.get(workspace, 'workspaceblobstore')\n",
    "# # iris_dataset = Dataset.Tabular.from_delimited_files(DataPath(datastore, 'iris.csv'))\n",
    "# diab_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'diabetes-data/diabetes.csv'))\n",
    "\n",
    "# train_step = PythonScriptStep(\n",
    "#     name=\"train_data\",\n",
    "#     script_name=\"train.py\",\n",
    "#     compute_target=cluster,\n",
    "#     inputs=[iris_dataset.as_named_input('iris').as_mount()]\n",
    "# )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment\n",
    "OK, you're ready build the pipeline from the steps you've defined and run it as an experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline is built.\n",
      "Created step Train and Register Model [8e123256][e6c8b05f-bb11-4e8e-9512-8bb6eb1392dc], (This step will run and generate new outputs)\n",
      "Submitted PipelineRun 316ecbae-595e-49c1-bed3-ca22d0a8b199\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/316ecbae-595e-49c1-bed3-ca22d0a8b199?wsid=/subscriptions/ff711122-6294-4fad-9d1f-bf505a51fc42/resourcegroups/mlproject/workspaces/myworkspace2&tid=2e646472-172b-4099-8fa9-b1ad0ebb7e3a\n",
      "Pipeline submitted for execution.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b9c177146594d20819e4cdbc54a22ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Failed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/316ecbae-595e-49c1-bed3-ca22d0a8b199?wsid=/subscriptions/ff711122-6294-4fad-9d1f-bf505a51fc42/resourcegroups/mlproject/workspaces/myworkspace2&tid=2e646472-172b-4099-8fa9-b1ad0ebb7e3a\", \"run_id\": \"316ecbae-595e-49c1-bed3-ca22d0a8b199\", \"run_properties\": {\"run_id\": \"316ecbae-595e-49c1-bed3-ca22d0a8b199\", \"created_utc\": \"2021-07-19T07:20:05.998371Z\", \"properties\": {\"azureml.runsource\": \"azureml.PipelineRun\", \"runSource\": \"SDK\", \"runType\": \"SDK\", \"azureml.parameters\": \"{}\"}, \"tags\": {\"azureml.pipelineComponent\": \"pipelinerun\"}, \"end_time_utc\": \"2021-07-19T07:20:46.794253Z\", \"status\": \"Failed\", \"log_files\": {\"logs/azureml/executionlogs.txt\": \"https://myworkspstorage73fec2c74.blob.core.windows.net/azureml/ExperimentRun/dcid.316ecbae-595e-49c1-bed3-ca22d0a8b199/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=sb6tiENI4Y4ICuAnUhV9yR4Bw4LmI%2BYkd9zE%2FxBw520%3D&st=2021-07-19T07%3A10%3A11Z&se=2021-07-19T15%3A20%3A11Z&sp=r\", \"logs/azureml/stderrlogs.txt\": \"https://myworkspstorage73fec2c74.blob.core.windows.net/azureml/ExperimentRun/dcid.316ecbae-595e-49c1-bed3-ca22d0a8b199/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=f5kz7vkZT7UvYo3hKXX0hn5IZvp%2F2R4llC5pM0dyZ3k%3D&st=2021-07-19T07%3A10%3A11Z&se=2021-07-19T15%3A20%3A11Z&sp=r\", \"logs/azureml/stdoutlogs.txt\": \"https://myworkspstorage73fec2c74.blob.core.windows.net/azureml/ExperimentRun/dcid.316ecbae-595e-49c1-bed3-ca22d0a8b199/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=%2F7Lx%2BkJn3NsTaOIzQHO6zp67Sdnb8D9SXjEufLa0fMo%3D&st=2021-07-19T07%3A10%3A11Z&se=2021-07-19T15%3A20%3A11Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/executionlogs.txt\", \"logs/azureml/stderrlogs.txt\", \"logs/azureml/stdoutlogs.txt\"]], \"run_duration\": \"0:00:40\", \"run_number\": \"5\", \"run_queued_details\": {\"status\": \"Failed\", \"details\": null}}, \"child_runs\": [{\"run_id\": \"afc710de-dca5-43cb-a5ad-72308b0bab92\", \"name\": \"Train and Register Model\", \"status\": \"Failed\", \"start_time\": \"2021-07-19T07:20:26.171344Z\", \"created_time\": \"2021-07-19T07:20:10.640673Z\", \"end_time\": \"2021-07-19T07:20:44.165079Z\", \"duration\": \"0:00:33\", \"run_number\": 6, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2021-07-19T07:20:10.640673Z\", \"is_reused\": \"\"}], \"children_metrics\": {\"categories\": null, \"series\": null, \"metricName\": null}, \"run_metrics\": [], \"run_logs\": \"[2021-07-19 07:20:10Z] Submitting 1 runs, first five are: 8e123256:afc710de-dca5-43cb-a5ad-72308b0bab92\\n[2021-07-19 07:20:46Z] Execution of experiment failed, update experiment status and cancel running nodes.\\n\", \"graph\": {\"datasource_nodes\": {\"a8e110f2\": {\"node_id\": \"a8e110f2\", \"name\": \"3dc5b4c2-d35d-4944-841b-2d19f47f9c88\"}}, \"module_nodes\": {\"8e123256\": {\"node_id\": \"8e123256\", \"name\": \"Train and Register Model\", \"status\": \"Failed\", \"_is_reused\": false, \"run_id\": \"afc710de-dca5-43cb-a5ad-72308b0bab92\"}}, \"edges\": [{\"source_node_id\": \"a8e110f2\", \"source_node_name\": \"3dc5b4c2-d35d-4944-841b-2d19f47f9c88\", \"source_name\": \"data\", \"target_name\": \"diabetes\", \"dst_node_id\": \"8e123256\", \"dst_node_name\": \"Train and Register Model\"}], \"child_runs\": [{\"run_id\": \"afc710de-dca5-43cb-a5ad-72308b0bab92\", \"name\": \"Train and Register Model\", \"status\": \"Failed\", \"start_time\": \"2021-07-19T07:20:26.171344Z\", \"created_time\": \"2021-07-19T07:20:10.640673Z\", \"end_time\": \"2021-07-19T07:20:44.165079Z\", \"duration\": \"0:00:33\", \"run_number\": 6, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2021-07-19T07:20:10.640673Z\", \"is_reused\": \"\"}]}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.32.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineRunId: 316ecbae-595e-49c1-bed3-ca22d0a8b199\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/316ecbae-595e-49c1-bed3-ca22d0a8b199?wsid=/subscriptions/ff711122-6294-4fad-9d1f-bf505a51fc42/resourcegroups/mlproject/workspaces/myworkspace2&tid=2e646472-172b-4099-8fa9-b1ad0ebb7e3a\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: afc710de-dca5-43cb-a5ad-72308b0bab92\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/afc710de-dca5-43cb-a5ad-72308b0bab92?wsid=/subscriptions/ff711122-6294-4fad-9d1f-bf505a51fc42/resourcegroups/mlproject/workspaces/myworkspace2&tid=2e646472-172b-4099-8fa9-b1ad0ebb7e3a\n",
      "StepRun( Train and Register Model ) Status: NotStarted\n",
      "StepRun( Train and Register Model ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_c04c3a53adfabc608040ca16160c8504493360f0b98b8fc2541bcb5a329dffb2_d.txt\n",
      "========================================================================================================================\n",
      "2021-07-19T07:20:23Z Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/myworkspace2/azureml/afc710de-dca5-43cb-a5ad-72308b0bab92/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/myworkspace2/azureml/afc710de-dca5-43cb-a5ad-72308b0bab92/caches/workspaceblobstore -o ro --file-cache-timeout-in-seconds=1000000 --cache-size-mb=89367 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/myworkspace2/azureml/afc710de-dca5-43cb-a5ad-72308b0bab92/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n",
      "2021-07-19T07:20:23Z Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/myworkspace2/azureml/afc710de-dca5-43cb-a5ad-72308b0bab92/mounts/workspaceblobstore\n",
      "2021-07-19T07:20:23Z The vmsize standard_d2_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      "2021-07-19T07:20:23Z Starting output-watcher...\n",
      "2021-07-19T07:20:23Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "2021-07-19T07:20:23Z Executing 'Copy ACR Details file' on 10.0.0.4\n",
      "2021-07-19T07:20:23Z Copy ACR Details file succeeded on 10.0.0.4. Output: \n",
      ">>>   \n",
      ">>>   \n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_79621f0dba9dd087fd8e11f646163a77\n",
      "Digest: sha256:f4570a0dda3306490525d5d92f935adca497cb9555ac2fd97fcb11ba782bdd11\n",
      "Status: Image is up to date for 36b9413743b849dbb607c868473eda05.azurecr.io/azureml/azureml_79621f0dba9dd087fd8e11f646163a77:latest\n",
      "36b9413743b849dbb607c868473eda05.azurecr.io/azureml/azureml_79621f0dba9dd087fd8e11f646163a77:latest\n",
      "2021-07-19T07:20:24Z The vmsize standard_d2_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      "2021-07-19T07:20:24Z Check if container afc710de-dca5-43cb-a5ad-72308b0bab92 already exist exited with 0, \n",
      "\n",
      "64b4db7b52ba995097dca14c9c32fb2fbbeb761fb5921027d1588868764831b7\n",
      "2021-07-19T07:20:24Z Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n",
      "2021-07-19T07:20:24Z containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-d9485e4113439b07468fc76fffc09ca5-5b48c201b48f5c17-01 -sshRequired=false] \n",
      "2021/07/19 07:20:24 Starting App Insight Logger for task:  containerSetup\n",
      "2021/07/19 07:20:24 Version: 3.0.01650.0004 Branch: .SourceBranch Commit: 37e4354\n",
      "2021/07/19 07:20:24 Entered ContainerSetupTask - Preparing infiniband\n",
      "2021/07/19 07:20:24 Starting infiniband setup\n",
      "2021/07/19 07:20:24 Python Version found is Python 3.6.2 :: Anaconda, Inc.\n",
      "\n",
      "2021/07/19 07:20:24 Returning Python Version as 3.6\n",
      "2021-07-19T07:20:24Z VMSize: standard_d2_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-18.04\n",
      "2021/07/19 07:20:24 VMSize: standard_d2_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-18.04\n",
      "2021/07/19 07:20:24 VMSize: standard_d2_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-18.04\n",
      "2021/07/19 07:20:24 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      "2021-07-19T07:20:24Z Not setting up Infiniband in Container\n",
      "2021/07/19 07:20:24 Not setting up Infiniband in Container\n",
      "2021/07/19 07:20:24 Not setting up Infiniband in Container\n",
      "2021/07/19 07:20:24 Python Version found is Python 3.6.2 :: Anaconda, Inc.\n",
      "\n",
      "2021/07/19 07:20:24 Returning Python Version as 3.6\n",
      "2021/07/19 07:20:24 sshd inside container not required for job, skipping setup.\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_c04c3a53adfabc608040ca16160c8504493360f0b98b8fc2541bcb5a329dffb2_d.txt\n",
      "===============================================================================================================\n",
      "[2021-07-19T07:20:34.687136] Entering job release\n",
      "[2021-07-19T07:20:35.554808] Starting job release\n",
      "[2021-07-19T07:20:35.556535] Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 130\n",
      "[2021-07-19T07:20:35.557072] job release stage : upload_datastore starting...\n",
      "[2021-07-19T07:20:35.565686] job release stage : start importing azureml.history._tracking in run_history_release.\n",
      "[2021-07-19T07:20:35.565775] job release stage : execute_job_release starting...\n",
      "[2021-07-19T07:20:35.566014] Entering context manager injector.\n",
      "[2021-07-19T07:20:35.567393] job release stage : upload_datastore completed...\n",
      "[2021-07-19T07:20:35.571239] job release stage : copy_batchai_cached_logs starting...\n",
      "[2021-07-19T07:20:35.571279] job release stage : copy_batchai_cached_logs completed...\n",
      "[2021-07-19T07:20:35.657986] job release stage : send_run_telemetry starting...\n",
      "[2021-07-19T07:20:35.693875] get vm size and vm region successfully.\n",
      "[2021-07-19T07:20:35.708425] get compute meta data successfully.\n",
      "[2021-07-19T07:20:35.813922] job release stage : execute_job_release completed...\n",
      "[2021-07-19T07:20:35.953721] post artifact meta request successfully.\n",
      "[2021-07-19T07:20:35.986975] upload compute record artifact successfully.\n",
      "[2021-07-19T07:20:35.987058] job release stage : send_run_telemetry completed...\n",
      "[2021-07-19T07:20:35.987464] Job release is complete\n",
      "\n",
      "StepRun(Train and Register Model) Execution Summary\n",
      "====================================================\n",
      "StepRun( Train and Register Model ) Status: Failed\n",
      "\n",
      "Warnings:\n",
      "{\n",
      "  \"error\": {\n",
      "    \"code\": \"UserError\",\n",
      "    \"severity\": null,\n",
      "    \"message\": \"AzureMLCompute job failed.\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\n\\tReason: Job failed with non-zero exit Code\",\n",
      "    \"messageFormat\": \"{Message}\",\n",
      "    \"messageParameters\": {\n",
      "      \"Message\": \"AzureMLCompute job failed.\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\n\\tReason: Job failed with non-zero exit Code\"\n",
      "    },\n",
      "    \"referenceCode\": null,\n",
      "    \"detailsUri\": null,\n",
      "    \"target\": null,\n",
      "    \"details\": [],\n",
      "    \"innerError\": {\n",
      "      \"code\": \"UserTrainingScriptFailed\",\n",
      "      \"innerError\": null\n",
      "    },\n",
      "    \"debugInfo\": null,\n",
      "    \"additionalInfo\": null\n",
      "  },\n",
      "  \"correlation\": {\n",
      "    \"operation\": \"2063143f9bf3cd4a8d35f57d186e7617\",\n",
      "    \"request\": \"f248c7534edd0247\"\n",
      "  },\n",
      "  \"environment\": \"westus2\",\n",
      "  \"location\": \"westus2\",\n",
      "  \"time\": \"2021-07-19T07:20:44.1022641+00:00\",\n",
      "  \"componentName\": \"execution-worker\"\n",
      "}\n"
     ]
    },
    {
     "ename": "ActivityFailedException",
     "evalue": "ActivityFailedException:\n\tMessage: Activity Failed:\n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"User program failed with FileNotFoundError: [Errno 2] No such file or directory: 'C:/Users/User/Desktop/Data/diabetes.csv'\",\n        \"messageParameters\": {},\n        \"detailsUri\": \"https://aka.ms/azureml-run-troubleshooting\",\n        \"details\": []\n    },\n    \"time\": \"0001-01-01T00:00:00.000Z\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"User program failed with FileNotFoundError: [Errno 2] No such file or directory: 'C:/Users/User/Desktop/Data/diabetes.csv'\\\",\\n        \\\"messageParameters\\\": {},\\n        \\\"detailsUri\\\": \\\"https://aka.ms/azureml-run-troubleshooting\\\",\\n        \\\"details\\\": []\\n    },\\n    \\\"time\\\": \\\"0001-01-01T00:00:00.000Z\\\"\\n}\"\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mActivityFailedException\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-116-cf41593419b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Pipeline submitted for execution.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mRunDetails\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline_run\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mpipeline_run\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait_for_completion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshow_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\azureml\\pipeline\\core\\run.py\u001b[0m in \u001b[0;36mwait_for_completion\u001b[1;34m(self, show_output, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[0;32m    292\u001b[0m                             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m                             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 294\u001b[1;33m                                 step_run.wait_for_completion(timeout_seconds=timeout_seconds - time_elapsed,\n\u001b[0m\u001b[0;32m    295\u001b[0m                                                              raise_on_error=raise_on_error)\n\u001b[0;32m    296\u001b[0m                             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\azureml\\pipeline\\core\\run.py\u001b[0m in \u001b[0;36mwait_for_completion\u001b[1;34m(self, show_output, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[0;32m    734\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mshow_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m                 return self._stream_run_output(timeout_seconds=timeout_seconds,\n\u001b[0m\u001b[0;32m    737\u001b[0m                                                raise_on_error=raise_on_error)\n\u001b[0;32m    738\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\azureml\\pipeline\\core\\run.py\u001b[0m in \u001b[0;36m_stream_run_output\u001b[1;34m(self, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[0;32m    823\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    824\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0merror\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mraise_on_error\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 825\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mActivityFailedException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_details\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    826\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal_details\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mActivityFailedException\u001b[0m: ActivityFailedException:\n\tMessage: Activity Failed:\n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"User program failed with FileNotFoundError: [Errno 2] No such file or directory: 'C:/Users/User/Desktop/Data/diabetes.csv'\",\n        \"messageParameters\": {},\n        \"detailsUri\": \"https://aka.ms/azureml-run-troubleshooting\",\n        \"details\": []\n    },\n    \"time\": \"0001-01-01T00:00:00.000Z\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"User program failed with FileNotFoundError: [Errno 2] No such file or directory: 'C:/Users/User/Desktop/Data/diabetes.csv'\\\",\\n        \\\"messageParameters\\\": {},\\n        \\\"detailsUri\\\": \\\"https://aka.ms/azureml-run-troubleshooting\\\",\\n        \\\"details\\\": []\\n    },\\n    \\\"time\\\": \\\"0001-01-01T00:00:00.000Z\\\"\\n}\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "from azureml.core import Experiment\n",
    "from azureml.pipeline.core import Pipeline\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "# Construct the pipeline\n",
    "pipeline_steps = [ train_step]\n",
    "pipeline = Pipeline(workspace=ws, steps=pipeline_steps)\n",
    "print(\"Pipeline is built.\")\n",
    "\n",
    "# Create an experiment and run the pipeline\n",
    "experiment = Experiment(workspace=ws, name = 'mslearn-diabetes-pipeline')\n",
    "pipeline_run = experiment.submit(pipeline, regenerate_outputs=True)\n",
    "print(\"Pipeline submitted for execution.\")\n",
    "RunDetails(pipeline_run).show()\n",
    "pipeline_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
